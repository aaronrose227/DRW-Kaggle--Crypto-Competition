{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":96164,"databundleVersionId":12993472,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-19T14:04:40.303649Z","iopub.execute_input":"2025-07-19T14:04:40.303824Z","iopub.status.idle":"2025-07-19T14:04:42.288839Z","shell.execute_reply.started":"2025-07-19T14:04:40.303807Z","shell.execute_reply":"2025-07-19T14:04:42.288152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DRW Crypto Market Prediction: Top-Percentile, Reproducible Pipeline\n\nimport numpy as np, pandas as pd, os, gc, warnings\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import make_scorer\nimport xgboost as xgb\n\nwarnings.filterwarnings(\"ignore\")\n\n# 1. Config and Feature List\nRAW_FEATS = [\n    'X863','X856','X598','X862','X385','X852','X603','X860','X674','X415','X345','X855','X174','X302','X178','X168','X612',\n    'buy_qty','sell_qty','volume','X888','X421','X333','bid_qty','ask_qty'\n]\nENGINEERED_FEATS = [\n    'volume_weighted_sell','buy_sell_ratio','selling_pressure','effective_spread_proxy'\n]\nALL_FEATS = RAW_FEATS + ENGINEERED_FEATS\n\nXGB_PARAMS = dict(\n    tree_method='hist',\n    max_depth=20,\n    max_leaves=12,\n    learning_rate=0.022,\n    n_estimators=1667,\n    subsample=0.066,\n    colsample_bytree=0.71,\n    gamma=1.71,\n    reg_alpha=39,\n    reg_lambda=75,\n    random_state=42,\n    predictor=\"gpu_predictor\",\n    n_jobs=-1,\n    verbosity=0\n)\n\nDECAY = 0.997  # Time decay factor for sample weights\n\ndef feature_engineering(df):\n    eps = 1e-8\n    df['volume_weighted_sell'] = df['sell_qty'] * df['volume']\n    df['buy_sell_ratio'] = df['buy_qty'] / (df['sell_qty'] + eps)\n    df['selling_pressure'] = df['sell_qty'] / (df['volume'] + eps)\n    df['effective_spread_proxy'] = (df['ask_qty'] - df['bid_qty']) / (df['ask_qty'] + df['bid_qty'] + eps)\n    # Replace inf with nan, then fill nan with zero\n    for f in ENGINEERED_FEATS:\n        df[f].replace([np.inf,-np.inf], np.nan, inplace=True)\n        df[f].fillna(0, inplace=True)\n    return df\n\ndef create_time_decay_weights(n, decay=DECAY):\n    \"\"\"Most recent rows have highest weights, oldest lowest.\"\"\"\n    return np.power(decay, 1 - np.arange(n) / (n - 1))\n\ndef load_data():\n    train = pd.read_parquet('/kaggle/input/drw-crypto-market-prediction/train.parquet')\n    test = pd.read_parquet('/kaggle/input/drw-crypto-market-prediction/test.parquet')\n    for c in RAW_FEATS:\n        if c not in train.columns:\n            train[c] = 0\n            test[c] = 0\n    train = feature_engineering(train)\n    test = feature_engineering(test)\n    X = train[ALL_FEATS].astype(np.float32)\n    y = train['label'].astype(np.float32)\n    X_test = test[ALL_FEATS].astype(np.float32)\n    sub = pd.read_csv('/kaggle/input/drw-crypto-market-prediction/sample_submission.csv')\n    return X, y, X_test, sub\n\ndef get_model_slices(n):\n    \"\"\"Return train slices for: all data, last 75%, last 50%.\"\"\"\n    slice_full = (0, n)\n    slice_75 = (n//4, n)\n    slice_50 = (n//2, n)\n    return [slice_full, slice_75, slice_50]\n\ndef train_and_predict(X, y, X_test):\n    N = len(X)\n    FOLDS = 3\n    cv = KFold(n_splits=FOLDS, shuffle=False)\n    oof_preds = [np.full(N, np.nan) for _ in range(3)]\n    test_preds = [np.zeros(X_test.shape[0]) for _ in range(3)]\n    slice_idxs = get_model_slices(N)\n    test_preds_per_fold = [[] for _ in range(3)]\n    oof_corrs = []\n\n    for fold, (tr_idx, va_idx) in enumerate(cv.split(X)):\n        for i, (start, end) in enumerate(slice_idxs):\n            if fold == 0 and i == 0: print(f\"  Slice {i}: rows {start} to {end}\")\n            idx_tr = tr_idx[tr_idx >= start]\n            idx_va = va_idx[(va_idx >= start) & (va_idx < end)]\n            if len(idx_tr) == 0 or len(idx_va) == 0:\n                continue\n            X_tr, y_tr = X.iloc[idx_tr], y.iloc[idx_tr]\n            X_va, y_va = X.iloc[idx_va], y.iloc[idx_va]\n            w_tr = create_time_decay_weights(len(X_tr))\n            model = xgb.XGBRegressor(**XGB_PARAMS)\n            model.fit(X_tr, y_tr, sample_weight=w_tr, verbose=False)\n            oof = model.predict(X_va)\n            oof_preds[i][idx_va] = oof\n            test_pred = model.predict(X_test)\n            test_preds_per_fold[i].append(test_pred)\n    # Aggregate fold test preds by mean\n    for i in range(3):\n        test_preds[i] = np.mean(test_preds_per_fold[i], axis=0)\n    # OOF pearson for each slice\n    for i, (start, end) in enumerate(slice_idxs):\n        idx = np.arange(N)[(np.arange(N) >= start) & (np.arange(N) < end)]\n        corr = np.corrcoef(y[idx], oof_preds[i][idx])[0,1]\n        oof_corrs.append(corr)\n        print(f\"Slice {i+1} OOF Pearson: {corr:.5f}\")\n    return oof_preds, test_preds, oof_corrs\n\ndef ensemble_and_submit(oof_corrs, test_preds, sub):\n    # Mean and weighted-mean ensemble\n    w = np.array(oof_corrs)\n    w = np.maximum(w, 0)  # don't allow negative weights\n    if w.sum() == 0: w = np.ones_like(w)\n    w = w / w.sum()\n    mean_pred = np.mean(test_preds, axis=0)\n    weighted_pred = np.average(test_preds, axis=0, weights=w)\n    # Pick best OOF\n    print(f\"OOF correlations: {oof_corrs}, weights: {w}\")\n    if np.sum(w) == 0 or np.mean(oof_corrs) >= np.dot(oof_corrs, w):\n        final_pred = mean_pred\n        print(\"Submitting mean-ensemble (simple average).\")\n    else:\n        final_pred = weighted_pred\n        print(\"Submitting weighted-ensemble (weighted by slice OOF).\")\n    sub['prediction'] = final_pred\n    sub.to_csv('/kaggle/working/submission.csv', index=False)\n    print(sub.head())\n    print(\"submission.csv saved!\")\n\n# Main run\nX, y, X_test, sub = load_data()\noof_preds, test_preds, oof_corrs = train_and_predict(X, y, X_test)\nensemble_and_submit(oof_corrs, test_preds, sub)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T14:04:42.290087Z","iopub.execute_input":"2025-07-19T14:04:42.290555Z","iopub.status.idle":"2025-07-19T14:08:32.823800Z","shell.execute_reply.started":"2025-07-19T14:04:42.290532Z","shell.execute_reply":"2025-07-19T14:08:32.823069Z"}},"outputs":[],"execution_count":null}]}